{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnEQNcPv14v3gabslE08a1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojakota17/Data-Mining-255/blob/main/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55bfcO1sjOZZ"
      },
      "source": [
        "# Use state of art libraries for Approximate nearest neighbor search for a  data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u9I_-AEja7O"
      },
      "source": [
        "> Dataset : https://making.lyst.com/lightfm/docs/_modules/lightfm/datasets/stackexchange.html\n",
        "\n",
        "> It is a stackexchange dataset consists of user-question interaction and question and tags item features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgjJSPJjjtZr"
      },
      "source": [
        "## Install the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l4lFmwbpEFl",
        "outputId": "b4d36a15-5d1d-4341-9eea-4b82db48b4cb"
      },
      "source": [
        "!pip install lightFM"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightFM\n",
            "  Downloading lightfm-1.16.tar.gz (310 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 133 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 153 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 204 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 215 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 225 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 235 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 245 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 256 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 266 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 276 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 286 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 296 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 307 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 310 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightFM) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightFM) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightFM) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightFM) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightFM) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightFM) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightFM) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightFM) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightFM) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightFM) (3.0.0)\n",
            "Building wheels for collected packages: lightFM\n",
            "  Building wheel for lightFM (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightFM: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=705362 sha256=59079be29e68bdb8cbf73cc4a3b2dbb6b67e7c19e8c674abd418f539f6c53b4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/56/28/5772a3bd3413d65f03aa452190b00898b680b10028a1021914\n",
            "Successfully built lightFM\n",
            "Installing collected packages: lightFM\n",
            "Successfully installed lightFM-1.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BGIslt-tG6V",
        "outputId": "5e49b22d-18bc-4b98-badc-cbc409b5a152"
      },
      "source": [
        "!pip install faiss"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss in /usr/local/lib/python3.7/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-oRAIipxMdz",
        "outputId": "4644ed31-09c5-48cc-b180-5eed2f9421c1"
      },
      "source": [
        "!apt install libomp-dev\n",
        "!python -m pip install --upgrade faiss faiss-gpu"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp-dev is already the newest version (5.0.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: faiss in /usr/local/lib/python3.7/dist-packages (1.5.3)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.7/dist-packages (1.7.1.post2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trJi5LV1dDcX",
        "outputId": "58623ed8-b39c-431e-a0da-963ce32c1d70"
      },
      "source": [
        "!python3 -m pip install --upgrade faiss-gpu==1.7.1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu==1.7.1\n",
            "  Downloading faiss_gpu-1.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 89.7 MB 16 kB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "  Attempting uninstall: faiss-gpu\n",
            "    Found existing installation: faiss-gpu 1.7.1.post2\n",
            "    Uninstalling faiss-gpu-1.7.1.post2:\n",
            "      Successfully uninstalled faiss-gpu-1.7.1.post2\n",
            "Successfully installed faiss-gpu-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfp5dsImhzoa"
      },
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.datasets import fetch_stackexchange\n",
        "import pickle\n",
        "import faiss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5JdNbz8jx7l"
      },
      "source": [
        "### Retrieve the dataset using fetch_stackexchange() and model it using LightFM to create a vector embedding of item and features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70qM43xPrckU"
      },
      "source": [
        "stackexchange = fetch_stackexchange('crossvalidated',indicator_features=True,tag_features=True)\n",
        "train = stackexchange['train']\n",
        "test = stackexchange['test']\n",
        "\n",
        "model = LightFM(learning_rate=0.05, loss='warp', no_components=64, item_alpha=0.001)\n",
        "model.fit_partial(train, item_features=stackexchange['item_features'], epochs=20 )\n",
        "\n",
        "item_vectors = stackexchange['item_features'] * model.item_embeddings"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlAd1mLKkD9t"
      },
      "source": [
        "> The item_features looks like this. (0,72360) 1.0, means that for question id 0, 72360 is the tag id(feature id) and the data here is 1( since its a sparse matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbY9yAS39acv",
        "outputId": "c93fa3ad-237a-449b-8618-c7f6a71678f2"
      },
      "source": [
        "print(stackexchange['item_features'])"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 0)\t1.0\n",
            "  (0, 72360)\t1.0\n",
            "  (0, 72361)\t1.0\n",
            "  (0, 72362)\t1.0\n",
            "  (1, 1)\t1.0\n",
            "  (1, 72363)\t1.0\n",
            "  (1, 72364)\t1.0\n",
            "  (2, 2)\t1.0\n",
            "  (2, 72365)\t1.0\n",
            "  (2, 72366)\t1.0\n",
            "  (3, 3)\t1.0\n",
            "  (3, 72363)\t1.0\n",
            "  (3, 72367)\t1.0\n",
            "  (4, 4)\t1.0\n",
            "  (4, 72368)\t1.0\n",
            "  (5, 5)\t1.0\n",
            "  (5, 72369)\t1.0\n",
            "  (5, 72370)\t1.0\n",
            "  (5, 72371)\t1.0\n",
            "  (5, 72372)\t1.0\n",
            "  (6, 6)\t1.0\n",
            "  (6, 72373)\t1.0\n",
            "  (7, 7)\t1.0\n",
            "  (7, 72374)\t1.0\n",
            "  (7, 72375)\t1.0\n",
            "  :\t:\n",
            "  (72354, 72837)\t1.0\n",
            "  (72354, 73124)\t1.0\n",
            "  (72354, 73164)\t1.0\n",
            "  (72355, 72355)\t1.0\n",
            "  (72355, 72436)\t1.0\n",
            "  (72355, 72548)\t1.0\n",
            "  (72355, 73090)\t1.0\n",
            "  (72356, 72356)\t1.0\n",
            "  (72356, 72440)\t1.0\n",
            "  (72356, 72513)\t1.0\n",
            "  (72356, 72731)\t1.0\n",
            "  (72356, 72796)\t1.0\n",
            "  (72356, 73057)\t1.0\n",
            "  (72357, 72357)\t1.0\n",
            "  (72357, 72404)\t1.0\n",
            "  (72357, 73399)\t1.0\n",
            "  (72358, 72358)\t1.0\n",
            "  (72358, 72406)\t1.0\n",
            "  (72358, 72411)\t1.0\n",
            "  (72358, 72747)\t1.0\n",
            "  (72358, 72920)\t1.0\n",
            "  (72359, 72359)\t1.0\n",
            "  (72359, 72503)\t1.0\n",
            "  (72359, 72507)\t1.0\n",
            "  (72359, 72616)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwFVv1jBkWFj"
      },
      "source": [
        "Open a pickle file in writing mode and store the feature labels, vector and item features, so that it can be used again without re-loading "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYQN-hPQtY6X"
      },
      "source": [
        "with open('stackexchange.pickle', 'wb') as f:\n",
        "    pickle.dump({\"name\": stackexchange['item_feature_labels'], \"vector\": item_vectors,\"features\":stackexchange['item_features']}, f)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1Tv5ue14Lz0",
        "outputId": "9b09ddb4-696d-47b2-8706-432ce18cd068"
      },
      "source": [
        "print(stackexchange['item_feature_labels'])"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['question_id:0' 'question_id:1' 'question_id:2' ... 'events'\n",
            " 'mutlivariate' 'sample-variance']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAmv2rQnkkOk"
      },
      "source": [
        "> Load the data from the pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-JYwvons38Q",
        "outputId": "56f9720e-5a5b-4214-edd4-5e8c8b1d0351"
      },
      "source": [
        "import pickle\n",
        "def load_data():\n",
        "    with open('stackexchange.pickle', 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "data = load_data()\n",
        "data"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': array(['question_id:0', 'question_id:1', 'question_id:2', ..., 'events',\n",
              "        'mutlivariate', 'sample-variance'], dtype='<U50'),\n",
              " 'vector': array([[ 0.16250771,  0.12406151, -0.08036248, ..., -0.11496134,\n",
              "         -0.02402518, -0.00704376],\n",
              "        [ 0.02717981,  0.25576022, -0.204706  , ..., -0.39978805,\n",
              "          0.15229318,  0.08870568],\n",
              "        [ 0.03993656,  0.03734043, -0.1159954 , ..., -0.30582762,\n",
              "         -0.12722601, -0.09749138],\n",
              "        ...,\n",
              "        [ 0.01483956,  0.05262152,  0.09099412, ...,  0.11744755,\n",
              "         -0.00935212,  0.000483  ],\n",
              "        [-0.11480884,  0.03977454,  0.11133081, ..., -0.04319084,\n",
              "          0.05634591,  0.16093293],\n",
              "        [ 0.05669373, -0.30438346, -0.00119976, ..., -0.12383866,\n",
              "         -0.09578706,  0.08885497]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RUDBzKmkp0s"
      },
      "source": [
        "### Function to retrieve the tags of a question based on question id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNG3QMlLkxQh"
      },
      "source": [
        "> As an eg, for question id :0, these are the tags : ['bayesian', 'prior', 'elicitation']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D9qicfZ4mpa",
        "outputId": "aa570e4a-a50e-4163-efc8-e40e7ec60b74"
      },
      "source": [
        "import scipy.sparse\n",
        "import random\n",
        "import itertools\n",
        "cx = scipy.sparse.coo_matrix(stackexchange['item_features'])\n",
        "def using_coo(index):\n",
        "    arr=[]\n",
        "       \n",
        "    for i,j,v in zip(cx.row, cx.col, cx.data):\n",
        "      if i==index and i != j:\n",
        "        arr.append(data['name'][j])\n",
        "      elif i>index:\n",
        "        break\n",
        "    return arr\n",
        "      # print(j,data['name'][j])\n",
        "using_coo(0)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bayesian', 'prior', 'elicitation']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyoX-aARH3B6"
      },
      "source": [
        "# 1. Locality Sensitive Hashing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hApKcEouH62f"
      },
      "source": [
        "class LSH():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def lsh_build(self, number_of_partition=8, search_in_x_partitions=2, subvector_size=8):\n",
        "        quantizer = faiss.IndexFlatL2(self.dimention)\n",
        "        self.index = faiss.IndexIVFPQ(quantizer, self.dimention, number_of_partition, search_in_x_partitions, subvector_size)\n",
        "        self.index.train(self.vectors)\n",
        "        self.index.add(self.vectors)\n",
        "\n",
        "      # to get similar tagged questions     \n",
        "    def get_similar_tagged_questions(self, vectors, k=12):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        similar_q_w_feature={}\n",
        "        q_features=[]\n",
        "        for i in indices[0]:\n",
        "          similar_q_w_feature[self.labels[i]]=using_coo(i)\n",
        "        return similar_q_w_feature\n",
        "        "
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgsop4nFk-b6"
      },
      "source": [
        "> Create an object of class lsh and call the get_similar_tagged_questions function to get similar tags for a particular vector. We can see the ouput below. The output shows 12 question id's which are similar to the input and their corresponding tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfrDCe4uIFpT",
        "outputId": "1550501f-32d2-40ca-f021-14265c565fab"
      },
      "source": [
        "index = LSH(data[\"vector\"], data[\"name\"])\n",
        "index.lsh_build()\n",
        "index.get_similar_tagged_questions(data[\"vector\"][0:2])"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question_id:0': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:10895': ['bayesian',\n",
              "  'frequentist',\n",
              "  'hypothesis-testing',\n",
              "  'confidence-interval',\n",
              "  'credible-interval'],\n",
              " 'question_id:1409': ['bayesian', 'prior', 'probability', 'meta-analysis'],\n",
              " 'question_id:14098': ['bayesian', 'nonparametric-bayes'],\n",
              " 'question_id:14480': ['bayesian', 'replication'],\n",
              " 'question_id:2021': ['bayesian', 'prior', 'terminology'],\n",
              " 'question_id:27035': ['bayesian', 'statistical-significance', 'ab-test'],\n",
              " 'question_id:3063': ['bayesian', 'multilevel-analysis'],\n",
              " 'question_id:3102': ['bayesian', 'multilevel-analysis', 'identifiability'],\n",
              " 'question_id:40715': ['bayesian',\n",
              "  'prior',\n",
              "  'estimation',\n",
              "  'parametric',\n",
              "  'uninformative-prior'],\n",
              " 'question_id:45542': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:9365': ['bayesian',\n",
              "  'prior',\n",
              "  'likelihood-function',\n",
              "  'inference',\n",
              "  'information']}"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqVbyUoWiyCA"
      },
      "source": [
        "# 2. Exhaustive Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISNxETNOwhAo"
      },
      "source": [
        "class ExhaustiveSearch():\n",
        "\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "        self.index = faiss.IndexFlatL2(vectors.shape[1])\n",
        "        self.index.add(self.vectors)\n",
        "        \n",
        "    # to get similar tagged questions      \n",
        "    def get_similar_tagged_questions(self,vectors,k=12):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        similar_q_w_feature={}\n",
        "        q_features=[]\n",
        "        for i in indices[0]:\n",
        "          similar_q_w_feature[self.labels[i]]=using_coo(i)\n",
        "        return similar_q_w_feature\n",
        "       "
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T__jPZYloQr"
      },
      "source": [
        "> Create an object of class ExhaustiveSearch and call the get_similar_tagged_questions function to get similar tags for a particular vector. We can see the ouput below. The output shows 12 question id's which are similar to the input and their corresponding tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6yoZEM0wwYQ",
        "outputId": "892d582f-c2f6-487c-b627-111af6655243"
      },
      "source": [
        "index = ExhaustiveSearch(data[\"vector\"], data[\"name\"])\n",
        "index.get_similar_tagged_questions(data['vector'][0:2])"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question_id:0': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:14826': ['bayesian', 'elicitation', 'r'],\n",
              " 'question_id:17409': ['bayesian', 'modeling', 'hierarchical-bayesian'],\n",
              " 'question_id:29382': ['bayesian',\n",
              "  'prior',\n",
              "  'elicitation',\n",
              "  'regression',\n",
              "  'hyperparameter'],\n",
              " 'question_id:29552': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:32951': ['bayesian', 'prior'],\n",
              " 'question_id:45542': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:53448': ['bayesian', 'prior'],\n",
              " 'question_id:60904': ['bayesian', 'prior'],\n",
              " 'question_id:62277': ['bayesian', 'prior', 'optimization'],\n",
              " 'question_id:65706': ['bayesian', 'prior'],\n",
              " 'question_id:71861': ['bayesian', 'prior']}"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXB2yWyGQ9vQ"
      },
      "source": [
        "# 3. Product Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIk9QOFgRM3s"
      },
      "source": [
        "class Prod_quant():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def prod_quant_build(self, number_of_partition=8, search_in_x_partitions=2, subvector_size=8):\n",
        "        quantizer = faiss.IndexFlatL2(self.dimention)\n",
        "        self.index = faiss.IndexIVFPQ(quantizer, \n",
        "                                      self.dimention, \n",
        "                                      number_of_partition, \n",
        "                                      search_in_x_partitions, \n",
        "                                      subvector_size)\n",
        "        self.index.train(self.vectors)\n",
        "        self.index.add(self.vectors)\n",
        "    # to get similar tagged questions    \n",
        "    def get_similar_tagged_questions(self, vectors, k=12):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        similar_q_w_feature={}\n",
        "        q_features=[]\n",
        "        for i in indices[0]:\n",
        "          similar_q_w_feature[self.labels[i]]=using_coo(i)\n",
        "        return similar_q_w_feature\n",
        "        "
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhB9BhUdljU_"
      },
      "source": [
        "> Create an object of class Prod_quant and call the get_similar_tagged_questions function to get similar tags for a particular vector. We can see the ouput below. The output shows 12 question id's which are similar to the input and their corresponding tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp5PsxDfRcgH",
        "outputId": "cf75dabe-5fad-45b5-8ec4-adbc415d3e9d"
      },
      "source": [
        "index = Prod_quant(data[\"vector\"], data[\"name\"])\n",
        "index.prod_quant_build()\n",
        "index.get_similar_tagged_questions(data[\"vector\"][0:2])"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question_id:0': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:10895': ['bayesian',\n",
              "  'frequentist',\n",
              "  'hypothesis-testing',\n",
              "  'confidence-interval',\n",
              "  'credible-interval'],\n",
              " 'question_id:1409': ['bayesian', 'prior', 'probability', 'meta-analysis'],\n",
              " 'question_id:14098': ['bayesian', 'nonparametric-bayes'],\n",
              " 'question_id:14480': ['bayesian', 'replication'],\n",
              " 'question_id:2021': ['bayesian', 'prior', 'terminology'],\n",
              " 'question_id:27035': ['bayesian', 'statistical-significance', 'ab-test'],\n",
              " 'question_id:3063': ['bayesian', 'multilevel-analysis'],\n",
              " 'question_id:3102': ['bayesian', 'multilevel-analysis', 'identifiability'],\n",
              " 'question_id:40715': ['bayesian',\n",
              "  'prior',\n",
              "  'estimation',\n",
              "  'parametric',\n",
              "  'uninformative-prior'],\n",
              " 'question_id:45542': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:9365': ['bayesian',\n",
              "  'prior',\n",
              "  'likelihood-function',\n",
              "  'inference',\n",
              "  'information']}"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_ZI9CYTRv4x"
      },
      "source": [
        "# 4. Trees and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHY25BnqSSOD",
        "outputId": "b2be34b6-790d-4f4d-c0f6-2817765badee"
      },
      "source": [
        "!pip install annoy"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.0.tar.gz (646 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 646 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.0-cp37-cp37m-linux_x86_64.whl size=391679 sha256=891c36d544f0a63892d40d917d5735ea29a124c59b500383e4b742050b2d59c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/e8/1e/7cc9ebbfa87a3b9f8ba79408d4d31831d67eea918b679a4c07\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLo0JCvRzhd"
      },
      "source": [
        "import annoy\n",
        "class Tree_graph_index():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def tree_build(self, number_of_trees=4):\n",
        "        self.index = annoy.AnnoyIndex(self.dimention)\n",
        "        for i, vec in enumerate(self.vectors):\n",
        "            self.index.add_item(i, vec.tolist())\n",
        "        self.index.build(number_of_trees)\n",
        "\n",
        "      # to get similar tagged questions     \n",
        "    def get_similar_tagged_questions(self, vector, k=12):\n",
        "        indices = self.index.get_nns_by_vector(vector.tolist(), k)\n",
        "        # print(indices)\n",
        "        similar_q_w_feature={}\n",
        "        q_features=[]\n",
        "        for i in indices:\n",
        "          similar_q_w_feature[self.labels[i]]=using_coo(i)\n",
        "        return similar_q_w_feature\n",
        "       "
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-p4HQTJly-X"
      },
      "source": [
        "> Create an object of class Tree_graph_index and call the get_similar_tagged_questions function to get similar tags for a particular vector. We can see the ouput below. The output shows 12 question id's which are similar to the input and their corresponding tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0DZQV51SFL8",
        "outputId": "7d21b31e-4990-4bc0-ca88-1b8630580321"
      },
      "source": [
        "index = Tree_graph_index(data[\"vector\"], data[\"name\"])\n",
        "index.tree_build()\n"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NnPXEI_cewL",
        "outputId": "d3e71277-2bf9-44f9-c4f2-17228c1d5fa6"
      },
      "source": [
        "index.get_similar_tagged_questions(data[\"vector\"][0])"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question_id:0': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:10471': ['mathematics'],\n",
              " 'question_id:13610': ['statistical-significance',\n",
              "  'hypothesis-testing',\n",
              "  't-test',\n",
              "  'multilevel-analysis'],\n",
              " 'question_id:17619': ['anova', 'interpretation'],\n",
              " 'question_id:21533': ['bayesian', 'topic-models'],\n",
              " 'question_id:22940': ['bayesian', 'modeling', 'hypothesis-testing'],\n",
              " 'question_id:22970': ['bayesian', 'likelihood-function'],\n",
              " 'question_id:29878': ['bayesian',\n",
              "  'hypothesis-testing',\n",
              "  'categorical-data',\n",
              "  'bayes'],\n",
              " 'question_id:37539': ['t-test', 'power'],\n",
              " 'question_id:53444': ['bayesian', 'prior', 'hypothesis-testing', 'python'],\n",
              " 'question_id:59680': ['bayesian',\n",
              "  'hypothesis-testing',\n",
              "  'hierarchical-bayesian'],\n",
              " 'question_id:59983': ['bayesian', 'mathematics']}"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TJ6DC1WcvAy"
      },
      "source": [
        "# 5. HNSW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxUKXwdZcovn",
        "outputId": "af2117c2-3c80-4061-c1b6-11ac04526047"
      },
      "source": [
        "!pip install  nmslib"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nmslib\n",
            "  Downloading nmslib-2.1.1-cp37-cp37m-manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from nmslib) (1.19.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib) (5.4.8)\n",
            "Installing collected packages: pybind11, nmslib\n",
            "Successfully installed nmslib-2.1.1 pybind11-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr6B67A7czyb"
      },
      "source": [
        "import nmslib\n",
        "class hnsw_index():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "    def hnsw_build(self):\n",
        "        self.index = nmslib.init(method='hnsw', space='cosinesimil')\n",
        "        self.index.addDataPointBatch(self.vectors)\n",
        "        self.index.createIndex({'post': 2})\n",
        "\n",
        "      # to get similar tagged questions     \n",
        "    def get_similar_tagged_questions(self, vector, k=12):\n",
        "        indices = self.index.knnQuery(vector, k=k)\n",
        "        similar_q_w_feature={}\n",
        "        q_features=[]\n",
        "        for i in indices[0]:\n",
        "          # similar_q_w_feature.append((self.labels[i], using_coo(i)))\n",
        "          similar_q_w_feature[self.labels[i]]=using_coo(i)\n",
        "        return similar_q_w_feature\n",
        "       "
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO-b4VdBl57N"
      },
      "source": [
        "> Create an object of class hnsw_index and call the get_similar_tagged_questions function to get similar tags for a particular vector. We can see the ouput below. The output shows 12 question id's which are similar to the input and their corresponding tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aaHBOaOeNU3"
      },
      "source": [
        "index = hnsw_index(data[\"vector\"], data[\"name\"])\n",
        "index.hnsw_build()"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwM4efg5fC-H",
        "outputId": "edf29ee8-6daa-48da-96a0-193f7347bd98"
      },
      "source": [
        "index.get_similar_tagged_questions(data[\"vector\"][0])"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question_id:0': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:14826': ['bayesian', 'elicitation', 'r'],\n",
              " 'question_id:22211': ['bayesian', 'power'],\n",
              " 'question_id:29382': ['bayesian',\n",
              "  'prior',\n",
              "  'elicitation',\n",
              "  'regression',\n",
              "  'hyperparameter'],\n",
              " 'question_id:29552': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:32673': ['bayesian', 'modeling'],\n",
              " 'question_id:45542': ['bayesian', 'prior', 'elicitation'],\n",
              " 'question_id:53448': ['bayesian', 'prior'],\n",
              " 'question_id:60904': ['bayesian', 'prior'],\n",
              " 'question_id:62277': ['bayesian', 'prior', 'optimization'],\n",
              " 'question_id:65706': ['bayesian', 'prior'],\n",
              " 'question_id:71861': ['bayesian', 'prior']}"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuuzEPi6ins_"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rNNkYtRmDoB"
      },
      "source": [
        "> HNSW and Exhaustive search have a similar output.\n",
        "\n",
        "> Product Quantization and LSH have a similar output.\n",
        "\n",
        "> Tree and Graphs output is different from others."
      ]
    }
  ]
}